{"cells":[{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["from langchain_community.document_loaders import DirectoryLoader, JSONLoader, TextLoader, UnstructuredFileLoader, UnstructuredHTMLLoader, UnstructuredMarkdownLoader\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","from langchain_community.vectorstores import FAISS\n","from langchain_community.embeddings import OllamaEmbeddings\n","import os\n","import subprocess"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[],"source":["def setup_ollama():\n","        \"\"\"\n","        Downloads (if necessary) and runs ollama locally\n","        \"\"\"\n","        # os.system(\"curl -fsSL https://ollama.com/install.sh | sh\")\n","        # os.system(\"export OLLAMA_HOST=localhost:8888\")\n","        os.system(\"sudo service ollama stop\")\n","        cmd = \"ollama serve\"\n","        with open(os.devnull, 'wb') as devnull:\n","                process = subprocess.Popen(cmd, shell=True, stdout=devnull, stderr=devnull)"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[],"source":["def get_file_types(directory):\n","        \"\"\"\n","        Traverses all of the files in specified directory and returns types of files that it finds\n","\n","        Args:\n","            directory (str): Path to directory\n","\n","        Returns:\n","            Set[str]: All of the file types that can be found in the directory\n","        \"\"\"\n","        file_types = set()\n","\n","        for filename in os.listdir(directory):\n","                if os.path.isfile(os.path.join(directory, filename)):\n","                        _, ext = os.path.splitext(filename)\n","                        file_types.add(ext)\n","        return file_types"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[],"source":["# Specified loader for each type of file found in the cyber data directory (so far)\n","loaders = {\n","    '.php': UnstructuredFileLoader,\n","    '.cs': UnstructuredFileLoader,\n","    '': UnstructuredFileLoader,\n","    '.c': UnstructuredFileLoader,\n","    '.html': UnstructuredHTMLLoader,\n","    '.md': UnstructuredMarkdownLoader,\n","    '.tzt': UnstructuredFileLoader,\n","    '.java': UnstructuredFileLoader,\n","    '.txt': TextLoader,\n","    '.ps1': UnstructuredFileLoader,\n","    '.delphi': UnstructuredFileLoader,\n","    '.asm': UnstructuredFileLoader,\n","    '.TXT': TextLoader,\n","    '.json': JSONLoader\n","}"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[],"source":["def create_directory_loader(file_type, directory_path):\n","        \"\"\"\n","        Creates and returns a DirectoryLoader using the loader specific to the file type provided\n","        \n","        Args:\n","            file_type (str): Type of file to make loader for\n","            directory_path (str): Path to directory\n","\n","        Returns:\n","            DirectoryLoader: loader for the files in the directory provided\n","        \"\"\"\n","        if file_type == '.json':\n","            loader_list = []\n","            for file_name in [file for file in os.listdir(directory_path) if file.endswith('.json')]:\n","                loader_list.append(JSONLoader(file_path=directory_path+'/'+file_name,jq_schema='.', text_content=False))\n","            return loader_list\n","        else:\n","            return DirectoryLoader(\n","            path=directory_path,\n","            glob=f\"**/*{file_type}\",\n","            loader_cls=loaders.get(file_type, UnstructuredFileLoader))"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[],"source":["def split_text(docs, chunk_size=512, chunk_overlap=50):\n","        \"\"\"\n","        Splits the given text into chunks of a specified maximum length using RecursiveCharacterTextSplitter.\n","        \n","        Parameters:\n","                text (str): The input text to be split.\n","                max_length (int): The maximum length of each chunk.\n","                chunk_overlap (int): The number of characters to overlap between chunks.\n","                \n","        Returns:\n","                List[str]: A list of text chunks.\n","        \"\"\"\n","        splitter = RecursiveCharacterTextSplitter(\n","                chunk_size=chunk_size,\n","                chunk_overlap=chunk_overlap\n","        )\n","        return splitter.split_documents(docs)"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[?25lpulling manifest ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest \n","pulling 819c2adf5ce6... 100% ▕████████████████▏ 669 MB                         \n","pulling c71d239df917... 100% ▕████████████████▏  11 KB                         \n","pulling b837481ff855... 100% ▕████████████████▏   16 B                         \n","pulling 38badd946f91... 100% ▕████████████████▏  408 B                         \n","verifying sha256 digest \n","writing manifest \n","removing any unused layers \n","success \u001b[?25h\n","OllamaEmbeddings: 100%|██████████| 20592/20592 [33:51<00:00, 10.13it/s]\n"]}],"source":["if __name__==\"__main__\":\n","        setup_ollama()\n","                \n","        DB_FAISS_PATH = '../vectorstore'\n","        DATA_PATH = '../../cyber_data'\n","        \n","        file_types = get_file_types(DATA_PATH)\n","        documents = []\n","        \n","        for file_type in file_types:\n","                if file_type.strip() != \"\":\n","                        if file_type == '.json':\n","                                loader_list = create_directory_loader(file_type, DATA_PATH)\n","                                for loader in loader_list:\n","                                        docs = loader.load()\n","                                        chunks = split_text(docs)\n","                                        if chunks != None and chunks != \"\" and len(chunks) > 0:\n","                                                documents.extend(chunks)\n","                        else:        \n","                                loader = create_directory_loader(file_type, DATA_PATH)\n","                                docs = loader.load()\n","                                chunks = split_text(docs)\n","                                if chunks != None and chunks != \"\" and len(chunks) > 0:\n","                                        documents.extend(chunks)\n","                                        \n","        for document in documents:\n","                document.page_content += ' Source: ' + document.metadata['source'].replace('/', '.').split('.')[-2]\n","        \n","        os.system(\"ollama pull mxbai-embed-large\")\n","        embeddings=OllamaEmbeddings(model=\"mxbai-embed-large\", show_progress=True)\n","        vectorstore = FAISS.from_documents(documents=documents, embedding=embeddings)\n","        vectorstore.save_local(DB_FAISS_PATH)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","import glob\n","import re\n","# Directory where files are located\n","directory = '../../cyber_data'\n","# Get a list of all files in the directory\n","files = glob.glob(directory + '*.txt')  # Only get .txt files\n","for file_path in files:\n","    # Extract filename from the path\n","    file_name = os.path.basename(file_path)\n","    # Check if the file starts with a number and ends with .txt\n","    if re.match(r'^\\d.*\\.txt$', file_name):\n","        # Open each file and read the first line\n","        with open(file_path, 'r', encoding='utf-8') as file:\n","            first_line = file.readline().strip()\n","        # Extract file extension\n","        file_ext = os.path.splitext(file_name)[1]\n","        # Create the new file name using the first line content\n","        new_file_name = os.path.join(directory, first_line + file_ext)\n","        # Rename the file\n","        try:\n","            os.rename(file_path, new_file_name)\n","            print(f'Renamed {file_name} to {first_line + file_ext}')\n","        except FileNotFoundError:\n","            print(f\"FileNotFoundError: {file_path} not found.\")\n","    else:\n","        print(f\"Skipping {file_name} - does not match renaming criteria.\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":2}
