{"cells":[{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[],"source":["from langchain_community.document_loaders import DirectoryLoader, JSONLoader, TextLoader, UnstructuredFileLoader, UnstructuredHTMLLoader, UnstructuredMarkdownLoader\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","from langchain_community.vectorstores import FAISS\n","from langchain_community.embeddings import OllamaEmbeddings\n","from streamlit_llama3_advanced import DB_FAISS_PATH\n","import os\n","import pathlib\n","import subprocess"]},{"cell_type":"code","execution_count":46,"metadata":{},"outputs":[],"source":["def setup_ollama():\n","        \"\"\"\n","        Downloads (if necessary) and runs ollama locally\n","        \"\"\"\n","        # os.system(\"curl -fsSL https://ollama.com/install.sh | sh\")\n","        # os.system(\"export OLLAMA_HOST=localhost:8888\")\n","        os.system(\"sudo service ollama stop\")\n","        cmd = \"ollama serve\"\n","        with open(os.devnull, 'wb') as devnull:\n","                process = subprocess.Popen(cmd, shell=True, stdout=devnull, stderr=devnull)"]},{"cell_type":"code","execution_count":47,"metadata":{},"outputs":[],"source":["def txt_file_rename(directory):\n","    \"\"\"\n","    Takes .txt files and renames them if they have a line containing title in them\n","\n","    Args:\n","        directory (str): path to directory where files are stored\n","    \"\"\"\n","    file_paths = pathlib.Path(directory).glob('*.txt')\n","    for file_path in file_paths:\n","        file_name = os.path.basename(file_path)\n","        file_ext = os.path.splitext(file_name)[1]\n","        with open(file_path, 'r', encoding='utf-8') as file:\n","            for line in file:\n","                segments = line.split(':')\n","                if 'title' in segments[0].lower() and len(segments) >= 2:\n","                    name = segments[1].strip()\n","                    new_file_name = os.path.join(directory, name + file_ext)\n","                    try:\n","                        print(f'Renamed {file_name} to {name}')\n","                        os.rename(file_path, new_file_name)\n","                        # print(f'Renamed {file_name} to {name}')\n","                    except FileNotFoundError:\n","                        print(f\"FileNotFoundError: {file_path} not found.\")\n","                    except PermissionError:\n","                        print(\"Permission denied: You don't have the necessary permissions to change the permissions of this file.\")\n","                    except NotADirectoryError:\n","                        print(f\"Not a directory: {new_file_name}\")"]},{"cell_type":"code","execution_count":48,"metadata":{},"outputs":[],"source":["def get_file_types(directory):\n","        \"\"\"\n","        Traverses all of the files in specified directory and returns types of files that it finds\n","\n","        Args:\n","            directory (str): Path to directory\n","\n","        Returns:\n","            Set[str]: All of the file types that can be found in the directory\n","        \"\"\"\n","        file_types = set()\n","\n","        for filename in os.listdir(directory):\n","                if os.path.isfile(os.path.join(directory, filename)):\n","                        _, ext = os.path.splitext(filename)\n","                        file_types.add(ext)\n","        return file_types"]},{"cell_type":"code","execution_count":49,"metadata":{},"outputs":[],"source":["# Specified loader for each type of file found in the cyber data directory (so far)\n","loaders = {\n","    '.php': UnstructuredFileLoader,\n","    '.cs': UnstructuredFileLoader,\n","    '': UnstructuredFileLoader,\n","    '.c': UnstructuredFileLoader,\n","    '.html': UnstructuredHTMLLoader,\n","    '.md': UnstructuredMarkdownLoader,\n","    '.tzt': UnstructuredFileLoader,\n","    '.java': UnstructuredFileLoader,\n","    '.txt': TextLoader,\n","    '.ps1': UnstructuredFileLoader,\n","    '.delphi': UnstructuredFileLoader,\n","    '.asm': UnstructuredFileLoader,\n","    '.TXT': TextLoader,\n","    '.json': JSONLoader\n","}"]},{"cell_type":"code","execution_count":50,"metadata":{},"outputs":[],"source":["def create_directory_loader(file_type, directory_path):\n","        \"\"\"\n","        Creates and returns a DirectoryLoader using the loader specific to the file type provided\n","        \n","        Args:\n","            file_type (str): Type of file to make loader for\n","            directory_path (str): Path to directory\n","\n","        Returns:\n","            DirectoryLoader: loader for the files in the directory provided\n","        \"\"\"\n","        if file_type == '.json':\n","            loader_list = []\n","            for file_name in [file for file in os.listdir(directory_path) if file.endswith('.json')]:\n","                loader_list.append(JSONLoader(file_path=directory_path+'/'+file_name,jq_schema='.', text_content=False))\n","            return loader_list\n","        else:\n","            return DirectoryLoader(\n","            path=directory_path,\n","            glob=f\"**/*{file_type}\",\n","            loader_cls=loaders.get(file_type, UnstructuredFileLoader))"]},{"cell_type":"code","execution_count":51,"metadata":{},"outputs":[],"source":["def split_text(docs, chunk_size=512, chunk_overlap=50):\n","        \"\"\"\n","        Splits the given text into chunks of a specified maximum length using RecursiveCharacterTextSplitter.\n","        \n","        Parameters:\n","                text (str): The input text to be split.\n","                max_length (int): The maximum length of each chunk.\n","                chunk_overlap (int): The number of characters to overlap between chunks.\n","                \n","        Returns:\n","                List[str]: A list of text chunks.\n","        \"\"\"\n","        splitter = RecursiveCharacterTextSplitter(\n","                chunk_size=chunk_size,\n","                chunk_overlap=chunk_overlap\n","        )\n","        return splitter.split_documents(docs)"]},{"cell_type":"code","execution_count":52,"metadata":{},"outputs":[],"source":["def load_documents(directory):\n","        \"\"\"\n","        Loads in files from ../data directory and returns them\n","\n","        Returns:\n","                List[Document]: Array of documents\n","        \"\"\"\n","        txt_file_rename(directory)\n","        file_types = get_file_types(directory)\n","        documents = []\n","        \n","        for file_type in file_types:\n","                if file_type.strip() != \"\":\n","                        if file_type == '.json':\n","                                loader_list = create_directory_loader(file_type, directory)\n","                                for loader in loader_list:\n","                                        docs = loader.load()\n","                                        chunks = split_text(docs)\n","                                        if chunks != None and chunks != \"\" and len(chunks) > 0:\n","                                                documents.extend(chunks)\n","                        else:        \n","                                loader = create_directory_loader(file_type, directory)\n","                                docs = loader.load()\n","                                chunks = split_text(docs)\n","                                if chunks != None and chunks != \"\" and len(chunks) > 0:\n","                                        documents.extend(chunks)\n","        return documents"]},{"cell_type":"code","execution_count":53,"metadata":{},"outputs":[],"source":["def create_knowledgeBase(directory, vectorstore):\n","    \"\"\"\n","    Loads in documents, splits into chunks, and vectorizes chunks and stores vectors under FAISS vector store\n","    \"\"\"\n","    documents = load_documents(directory)\n","    os.system(\"ollama pull mxbai-embed-large\")\n","    embeddings=OllamaEmbeddings(model=\"mxbai-embed-large\", show_progress=True)\n","    vectorstore = FAISS.from_documents(documents=documents, embedding=embeddings)\n","    if os.path.exists(DB_FAISS_PATH + '/index.faiss'):\n","        old_vectorstore = FAISS.load_local(DB_FAISS_PATH, embeddings)\n","        old_vectorstore.merge_from(DB_FAISS_PATH)\n","        old_vectorstore.save_local(DB_FAISS_PATH)\n","    else:\n","        vectorstore.save_local(DB_FAISS_PATH)"]},{"cell_type":"code","execution_count":54,"metadata":{},"outputs":[],"source":["def move_files(directory):\n","    file_paths = pathlib.Path(directory).glob('*.txt')\n","    new_path = '../../processed_cyber_data'\n","    for file_path in file_paths:\n","        file_name = os.path.basename(file_path)\n","        file_ext = os.path.splitext(file_name)[1]\n","        os.replace(file_path, new_path+file_name+file_ext)"]},{"cell_type":"code","execution_count":55,"metadata":{},"outputs":[],"source":["if __name__==\"__main__\":\n","        setup_ollama()\n","        DB_FAISS_PATH = '../vectorstore'\n","        DATA_PATH = '../../processed_cyber_data'\n","        # create_knowledgeBase(DATA_PATH, DB_FAISS_PATH)\n","        move_files(DATA_PATH)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":2}
