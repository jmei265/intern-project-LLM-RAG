{"cells":[{"cell_type":"markdown","metadata":{},"source":["mport Essential dependencies"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import streamlit as sl\n","from langchain_community.document_loaders import PyPDFLoader\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","from langchain_community.vectorstores import FAISS\n","from langchain_openai import OpenAIEmbeddings\n","from langchain.chains import RetrievalQA\n","from langchain.prompts import ChatPromptTemplate\n","from langchain_core.output_parsers import StrOutputParser\n","from langchain_core.runnables import RunnablePassthrough"]},{"cell_type":"markdown","metadata":{},"source":["unction to load the vectordatabase"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["def load_knowledgeBase():\n","        embeddings=OpenAIEmbeddings(api_key=os.environ['API_key'] )\n","        DB_FAISS_PATH = '../vectorstore'\n","        db = FAISS.load_local(DB_FAISS_PATH, embeddings)\n","        return db\n","        \n","#function to load the OPENAI LLM\n","def load_llm():\n","        from langchain_openai import ChatOpenAI\n","        llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0, api_key=os.environ['API_key'] )\n","        return llm"]},{"cell_type":"markdown","metadata":{},"source":["reating prompt template using langchain"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["def load_prompt():\n","        prompt = \"\"\" You need to answer the question in the sentence as same as in the  pdf content. . \n","        Given below is the context and question of the user.\n","        context = {context}\n","        question = {question}\n","        if the answer is not in the pdf answer \"Sorry, I'm not sure how to respond to this\"\n","         \"\"\"\n","        prompt = ChatPromptTemplate.from_template(prompt)\n","        return prompt"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["def format_docs(docs):\n","        return \"\\n\\n\".join(doc.page_content for doc in docs)"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-07-09 19:50:51.427 \n","  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n","  command:\n","\n","    streamlit run /home/ubuntu/.local/lib/python3.8/site-packages/ipykernel_launcher.py [ARGUMENTS]\n","2024-07-09 19:50:51.429 Session state does not function when running a script without `streamlit run`\n"]},{"ename":"ValidationError","evalue":"1 validation error for OpenAIEmbeddings\n__root__\n  Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass `openai_api_key` as a named parameter. (type=value_error)","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)","Cell \u001b[0;32mIn[5], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAPI_key\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m sl\u001b[38;5;241m.\u001b[39mtext_input(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEnter API key\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m sl\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mü§ñ You can chat by Entering your queries \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m knowledgeBase\u001b[38;5;241m=\u001b[39m\u001b[43mload_knowledgeBase\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m llm\u001b[38;5;241m=\u001b[39mload_llm()\n\u001b[1;32m     10\u001b[0m prompt\u001b[38;5;241m=\u001b[39mload_prompt()\n","Cell \u001b[0;32mIn[2], line 2\u001b[0m, in \u001b[0;36mload_knowledgeBase\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_knowledgeBase\u001b[39m():\n\u001b[0;32m----> 2\u001b[0m         embeddings\u001b[38;5;241m=\u001b[39m\u001b[43mOpenAIEmbeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menviron\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAPI_key\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m         DB_FAISS_PATH \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../vectorstore\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      4\u001b[0m         db \u001b[38;5;241m=\u001b[39m FAISS\u001b[38;5;241m.\u001b[39mload_local(DB_FAISS_PATH, embeddings)\n","File \u001b[0;32m~/.local/lib/python3.8/site-packages/pydantic/main.py:341\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[0;34m()\u001b[0m\n","\u001b[0;31mValidationError\u001b[0m: 1 validation error for OpenAIEmbeddings\n__root__\n  Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass `openai_api_key` as a named parameter. (type=value_error)"]}],"source":["import os\n","\n","if __name__=='__main__':\n","        sl.header(\"welcome to the üìùPDF bot\")\n","        sl.write(\"Please enter your API key: \")\n","        os.environ['API_key'] = sl.text_input('Enter API key')\n","        sl.write(\"ü§ñ You can chat by Entering your queries \")\n","        knowledgeBase=load_knowledgeBase()\n","        llm=load_llm()\n","        prompt=load_prompt()\n","        \n","        query=sl.text_input('Enter some text')\n","        \n","        \n","        if(query):\n","                #getting only the chunks that are similar to the query for llm to produce the output\n","                similar_embeddings=knowledgeBase.similarity_search(query)\n","                similar_embeddings=FAISS.from_documents(documents=similar_embeddings, embedding=OpenAIEmbeddings(api_key=os.environ['API_key'] ))\n","                \n","                #creating the chain for integrating llm,prompt,stroutputparser\n","                retriever = similar_embeddings.as_retriever()\n","                rag_chain = (\n","                        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n","                        | prompt\n","                        | llm\n","                        | StrOutputParser()\n","                    )\n","                \n","                response=rag_chain.invoke(query)\n","                sl.write(response)\n","        "]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":2}
